{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H2Jqf2DCij1I"
   },
   "source": [
    "# Importing Packages and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Z5UDXk0oBkAB"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import copy\n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZW_6AA1GW5ze",
    "outputId": "3e041561-c378-496a-a062-95c48ecca402"
   },
   "outputs": [],
   "source": [
    "# Run to access your drive from google colab\n",
    "if not LOCAL:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    PATH_PREFIX = 'drive/MyDrive/'\n",
    "else:\n",
    "    PATH_PREFIX = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hMQ_OtLFF8Ho",
    "outputId": "4eded848-e86a-41de-a822-cc816fbc3991"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yc/p4crn8cj0tz82_rx5_032qvw0000gn/T/ipykernel_93589/2593376703.py:2: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  prem_league_data = pd.read_csv(PATH_PREFIX + 'data/cleaned_merged_seasons.csv')\n"
     ]
    }
   ],
   "source": [
    "# Importing the main data\n",
    "prem_league_data = pd.read_csv(PATH_PREFIX + 'data/cleaned_merged_seasons.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ezDKnkfhDn_q"
   },
   "source": [
    "# Merging in 2018-19 and 2019-20 seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Qe_AlZp3DAO0"
   },
   "outputs": [],
   "source": [
    "merged_2018_19 = pd.read_csv(PATH_PREFIX + 'data/2018-19/gws/merged_gw.csv', encoding='iso-8859-1')\n",
    "merged_2019_20 = pd.read_csv(PATH_PREFIX + 'data/2019-20/gws/merged_gw.csv', encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "JSLGcJl9DTqx"
   },
   "outputs": [],
   "source": [
    "df_19 = merged_2018_19[['name', 'assists', 'bonus', 'bps', 'clean_sheets',\n",
    "                        'creativity', 'element', 'fixture', 'goals_conceded', 'goals_scored', 'ict_index',\n",
    "                        'influence', 'kickoff_time', 'minutes', 'opponent_team', 'own_goals', 'penalties_missed',\n",
    "                        'penalties_saved', 'red_cards', 'round', 'saves', 'selected', 'team_a_score', 'team_h_score',\n",
    "                        'threat', 'total_points', 'transfers_balance', 'transfers_in', 'transfers_out', 'value', 'was_home',\n",
    "                        'yellow_cards', 'GW']].copy()\n",
    "df_19['season_x'] = '2018-19'\n",
    "df_19['team_x'] = np.nan\n",
    "df_19['position'] = np.nan\n",
    "\n",
    "df_19['name'] = df_19['name'].apply(lambda x: x[:x.rfind('_')].replace('_', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "7ISX-LcmDhMK"
   },
   "outputs": [],
   "source": [
    "df_20 = merged_2019_20[['name', 'assists', 'bonus', 'bps', 'clean_sheets',\n",
    "                        'creativity', 'element', 'fixture', 'goals_conceded', 'goals_scored', 'ict_index',\n",
    "                        'influence', 'kickoff_time', 'minutes', 'opponent_team', 'own_goals', 'penalties_missed',\n",
    "                        'penalties_saved', 'red_cards', 'round', 'saves', 'selected', 'team_a_score', 'team_h_score',\n",
    "                        'threat', 'total_points', 'transfers_balance', 'transfers_in', 'transfers_out', 'value', 'was_home',\n",
    "                        'yellow_cards', 'GW']].copy()\n",
    "df_20['season_x'] = '2019-20'\n",
    "df_20['team_x'] = np.nan\n",
    "df_20['position'] = np.nan\n",
    "df_20['name'] = df_20['name'].apply(lambda x: x[:x.rfind('_')].replace('_', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "mO3Bt1c0Eqj6"
   },
   "outputs": [],
   "source": [
    "overall_df = pd.concat([prem_league_data, df_19, df_20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aA2Q0XDE25jQ"
   },
   "source": [
    "# Fixing special characters in names in the 2019-20 season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "n19hihaKvoXq"
   },
   "outputs": [],
   "source": [
    "# Mapping special characters\n",
    "spec_char_dict = {\n",
    "  'Ã¡':'á',\n",
    "  'Ã\\x81':'Á',\n",
    "  'Ã©':'é',\n",
    "  'Ã\\xad':'í',\n",
    "  'Ã³':'ó',\n",
    "  'Ãº':'ú',\n",
    "  'Ã¤':'ä',\n",
    "  'Ã«':'ë',\n",
    "  'Ã¯':'ï',\n",
    "  'Ã¶':'ö',\n",
    "  'Ã\\x96':'Ö',\n",
    "  'Ã¼':'ü',\n",
    "  'Ã£':'ã',\n",
    "  'Ã\\x9f':'ß',\n",
    "  'Ã§':'ç',\n",
    "  'Ä\\x87':'ć',\n",
    "  'Ã\\x87':'Ç',\n",
    "  'Ã±':'ñ',\n",
    "  'Ã¸':'ø',\n",
    "  'Ã\\x98':'Ø',\n",
    "  'Å¡':'š'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "spOunrNS3a_0"
   },
   "outputs": [],
   "source": [
    "# Pulling a list of all the names with special characters to fix\n",
    "# spec_char_names = df['name'][(df['season_x'] == '2019-20') & (df['team_x'].isnull())].unique()\n",
    "# The line above only works if you run it after getting the missing team info. I want to run the fix before joining on team info that way the join will work and I don't have to repeat it\n",
    "# Because of this, I'm hard coding the fix\n",
    "\n",
    "spec_char_names = ['Abdoulaye DoucourÃ©', 'Adama TraorÃ©',\n",
    "       'AdriÃ¡n San Miguel del Castillo', 'Alexis SÃ¡nchez',\n",
    "       'AndrÃ© Filipe Tavares Gomes', 'Antonio RÃ¼diger', 'Ayoze PÃ©rez',\n",
    "       'Bernard AnÃ\\xadcio Caldeira Duarte', 'Carlos SÃ¡nchez',\n",
    "       'Cheikhou KouyatÃ©', 'CÃ©dric Soares', 'CÃ©sar Azpilicueta',\n",
    "       'Daniel Ceballos FernÃ¡ndez', 'Davinson SÃ¡nchez', 'Davy PrÃ¶pper',\n",
    "       'Djibril SidibÃ©', 'Emiliano BuendÃ\\xada', 'Emiliano MartÃ\\xadnez',\n",
    "       'Fabian SchÃ¤r', 'FabiÃ¡n Balbuena', 'Federico FernÃ¡ndez',\n",
    "       'Francisco FemenÃ\\xada Far', 'FrÃ©dÃ©ric Guilbert', 'GaÃ«tan Bong',\n",
    "       'Georges-KÃ©vin Nkoudou', 'HÃ©ctor BellerÃ\\xadn', 'HÃ©lder Costa',\n",
    "       'Ilkay GÃ¼ndogan', 'IsmaÃ¯la Sarr', 'Javier HernÃ¡ndez BalcÃ¡zar',\n",
    "       'JesÃºs Vallejo LÃ¡zaro', 'Joelinton CÃ¡ssio ApolinÃ¡rio de Lira',\n",
    "       'Jonas LÃ¶ssl', 'Jose Luis Mato SanmartÃ\\xadn',\n",
    "       'JosÃ© Diogo Dalot Teixeira', 'JosÃ© Heriberto Izquierdo Mena',\n",
    "       'JosÃ© Ignacio Peleteiro Romallo',\n",
    "       'JosÃ© Ã\\x81ngel EsmorÃ\\xads Tasende', 'JosÃ© Holebas',\n",
    "       'JoÃ£o Filipe Iria Santos Moutinho', 'JoÃ£o Pedro Cavaco Cancelo',\n",
    "       'JÃ¼rgen Locadia', 'Leroy SanÃ©', 'MartÃ\\xadn Montoya',\n",
    "       'Mesut Ã\\x96zil', 'Miguel AlmirÃ³n', 'Muhamed BeÅ¡iÄ\\x87',\n",
    "       \"N'Golo KantÃ©\", 'Nathan AkÃ©', 'Nicolas PÃ©pÃ©',\n",
    "       'NicolÃ¡s Otamendi', 'Onel HernÃ¡ndez', 'Pascal GroÃ\\x9f',\n",
    "       'Pedro RodrÃ\\xadguez Ledesma', 'Pierre-Emile HÃ¸jbjerg',\n",
    "       'RaÃºl JimÃ©nez', 'Romain SaÃ¯ss',\n",
    "       'Rui Pedro dos Santos PatrÃ\\xadcio', 'RÃºben Diogo da Silva Neves',\n",
    "       'RÃºben GonÃ§alo Silva Nascimento Vinagre', 'Sadio ManÃ©',\n",
    "       'Sebastian PrÃ¶dl', 'Sergio AgÃ¼ero', 'SÃ©bastien Haller',\n",
    "       'Victor LindelÃ¶f', 'VÃ\\xadctor Camarasa', 'Ã\\x87aglar SÃ¶yÃ¼ncÃ¼',\n",
    "       'Ã\\x98rjan Nyland', 'JoÃ£o Pedro Junqueira de Jesus',\n",
    "       'GonÃ§alo Bento Soares Cardoso', 'Bruno AndrÃ© Cavaco Jordao',\n",
    "       'JosÃ© Reina', 'Pablo MarÃ\\xad', 'Borja GonzÃ¡lez TomÃ¡s',\n",
    "       'JoÃ£o Manuel Neves VirgÃ\\xadnia', 'Adalberto PeÃ±aranda']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "AOuBlC5C7bfC"
   },
   "outputs": [],
   "source": [
    "# Fixing special characters\n",
    "fixed_names = []\n",
    "\n",
    "for name in spec_char_names:\n",
    "  for key, value in spec_char_dict.items():\n",
    "      name = name.replace(key, value)\n",
    "  fixed_names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "UF_A6tPk7twD"
   },
   "outputs": [],
   "source": [
    "# Making a dictionary of corrected names\n",
    "corrected_name_dict = {spec_char_names[i]: fixed_names[i] for i in range(len(spec_char_names))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "UflLByH-79pI"
   },
   "outputs": [],
   "source": [
    "# Replacing all special character names in overall_df with the corrected names\n",
    "overall_df['name'] = overall_df['name'].replace(corrected_name_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "stlflysXkDzf"
   },
   "source": [
    "# Get missing team data for 2016-17, 2017-18, 2018-19, and 2019-20 seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "WkfUXRSJGZsx"
   },
   "outputs": [],
   "source": [
    "# Get list of teams by season\n",
    "teams = pd.read_csv(PATH_PREFIX + 'data/master_team_list.csv')\n",
    "teams_2016 = teams[teams.season=='2016-17']\n",
    "teams_2017 = teams[teams.season=='2017-18']\n",
    "teams_2018 = teams[teams.season=='2018-19']\n",
    "teams_2019 = teams[teams.season=='2019-20']\n",
    "\n",
    "# Get 2016 players and team data\n",
    "players_2016 = pd.read_csv(PATH_PREFIX + 'data/2016-17/players_raw.csv')\n",
    "players_2016['name'] = players_2016.first_name + ' ' + players_2016.second_name\n",
    "players_2016 = players_2016[['name', 'team']]\n",
    "players_2016_merged = players_2016.merge(teams_2016, how='left', on='team')\n",
    "\n",
    "df = overall_df.merge(players_2016_merged, how='left', left_on=['season_x', 'name'], right_on=['season', 'name'])\n",
    "df['team_x'] = np.where(~df['team_name'].isnull(),df['team_name'],df['team_x'])\n",
    "df.drop(columns=['team', 'season', 'team_name'], inplace=True)\n",
    "\n",
    "# Get 2017 players and team data\n",
    "players_2017 = pd.read_csv(PATH_PREFIX + 'data/2017-18/players_raw.csv')\n",
    "players_2017['name'] = players_2017.first_name + ' ' + players_2017.second_name\n",
    "players_2017 = players_2017[['name', 'team']]\n",
    "players_2017_merged = players_2017.merge(teams_2017, how='left', on='team')\n",
    "\n",
    "df = df.merge(players_2017_merged, how='left', left_on=['season_x', 'name'], right_on=['season', 'name'])\n",
    "df['team_x'] = np.where(~df['team_name'].isnull(),df['team_name'], df['team_x'])\n",
    "df.drop(columns=['team', 'season', 'team_name'], inplace=True)\n",
    "\n",
    "# Get 2018 players and team data\n",
    "players_2018 = pd.read_csv(PATH_PREFIX + 'data/2018-19/players_raw.csv')\n",
    "players_2018['name'] = players_2018.first_name + ' ' + players_2018.second_name\n",
    "players_2018 = players_2018[['name', 'team']]\n",
    "players_2018_merged = players_2018.merge(teams_2018, how='left', on='team')\n",
    "\n",
    "df = df.merge(players_2018_merged, how='left', left_on=['season_x', 'name'], right_on=['season', 'name'])\n",
    "df['team_x'] = np.where(~df['team_name'].isnull(),df['team_name'], df['team_x'])\n",
    "df.drop(columns=['team', 'season', 'team_name'], inplace=True)\n",
    "\n",
    "# Get 2019 players and team data\n",
    "players_2019 = pd.read_csv(PATH_PREFIX + 'data/2019-20/players_raw.csv')\n",
    "players_2019['name'] = players_2019.first_name + ' ' + players_2019.second_name\n",
    "players_2019 = players_2019[['name', 'team']]\n",
    "players_2019_merged = players_2019.merge(teams_2019, how='left', on='team')\n",
    "\n",
    "df = df.merge(players_2019_merged, how='left', left_on=['season_x', 'name'], right_on=['season', 'name'])\n",
    "df['team_x'] = np.where(~df['team_name'].isnull(),df['team_name'], df['team_x'])\n",
    "df.drop(columns=['team', 'season', 'team_name'], inplace=True)\n",
    "\n",
    "# Fixing missing team info for David de Gea and Caglar Söyüncü manually\n",
    "mask = ((df.season_x == '2017-18') | (df.season_x == '2018-19')) & ((df.name==\"David de Gea\") | (df.name==\"David De Gea\"))\n",
    "df.loc[mask, 'team_x'] = 'Man Utd'\n",
    "\n",
    "mask = (df.season_x == '2018-19') & (df.name==\"Caglar Söyüncü\")\n",
    "df.loc[mask, 'team_x'] = 'Leicester'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U7TF6pynOivO"
   },
   "source": [
    "# Fill Missing Position Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "JyHMK6hEy-OF"
   },
   "outputs": [],
   "source": [
    "fill_pos = pd.read_csv(PATH_PREFIX + 'data/mpos.csv')\n",
    "fill_pos.columns = ['dirty_name', 'clean_name', 'scrape_position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "wH0G8X57sBrw"
   },
   "outputs": [],
   "source": [
    "# clean names again\n",
    "df['name'] = df['name'].replace(corrected_name_dict)\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "\n",
    "def normalize_string(text):\n",
    "    # Strip leading/trailing whitespace\n",
    "    text = text.strip()\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Replace multiple spaces with a single space\n",
    "    text = ' '.join(text.split())\n",
    "    # Normalize unicode characters to the closest ASCII representation\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('ascii')\n",
    "    return text\n",
    "\n",
    "# Normalizing names, easier than removing special chars, suggest we use the normalized name col\n",
    "df['name_normalized'] = df['name'].apply(normalize_string)\n",
    "fill_pos['name_normalized'] = fill_pos['clean_name'].apply(normalize_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "hbG1C_HPI6W-"
   },
   "outputs": [],
   "source": [
    "# Create a dictionary to use for filling in missing names\n",
    "fill_pos[['name_normalized', 'scrape_position']].to_dict()\n",
    "pos_dict = pd.Series(fill_pos['scrape_position'].values, index=fill_pos['name_normalized']).to_dict()\n",
    "# Katherine note - why are these here?\n",
    "pos_dict.update({\n",
    "    'greg cunninghamm': 'DEF',\n",
    "    'muhamed besic': 'MID',\n",
    "    'zeze steven sessegnon': 'DEF',\n",
    "  }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "irIhfMuDwYb7"
   },
   "outputs": [],
   "source": [
    "# Filling nulls with a \"missing position\" tag\n",
    "df['position'] = df['position'].fillna('no_pos')\n",
    "\n",
    "# Filling missing positions using the dictionary created above\n",
    "def fill_missing_position(row):\n",
    "  if row['position'] == 'no_pos':\n",
    "    row['position'] = pos_dict.get(row['name_normalized'], \"no_position\")\n",
    "  return row\n",
    "\n",
    "df = df.apply(fill_missing_position, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 99
    },
    "id": "FzrC62JVKHio",
    "outputId": "c0feb367-1fe9-4f0b-be04-d89c9e891ccf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season_x</th>\n",
       "      <th>name</th>\n",
       "      <th>position</th>\n",
       "      <th>team_x</th>\n",
       "      <th>assists</th>\n",
       "      <th>bonus</th>\n",
       "      <th>bps</th>\n",
       "      <th>clean_sheets</th>\n",
       "      <th>creativity</th>\n",
       "      <th>element</th>\n",
       "      <th>...</th>\n",
       "      <th>threat</th>\n",
       "      <th>total_points</th>\n",
       "      <th>transfers_balance</th>\n",
       "      <th>transfers_in</th>\n",
       "      <th>transfers_out</th>\n",
       "      <th>value</th>\n",
       "      <th>was_home</th>\n",
       "      <th>yellow_cards</th>\n",
       "      <th>GW</th>\n",
       "      <th>name_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [season_x, name, position, team_x, assists, bonus, bps, clean_sheets, creativity, element, fixture, goals_conceded, goals_scored, ict_index, influence, kickoff_time, minutes, opponent_team, opp_team_name, own_goals, penalties_missed, penalties_saved, red_cards, round, saves, selected, team_a_score, team_h_score, threat, total_points, transfers_balance, transfers_in, transfers_out, value, was_home, yellow_cards, GW, name_normalized]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 38 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validating that all players have position data - remove at the end\n",
    "df[df.position == 'no_position']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7weZdn3nEAnQ"
   },
   "source": [
    "# Renaming messy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "a543AdOsEABc"
   },
   "outputs": [],
   "source": [
    "df.rename(columns={\"season_x\": \"season\", \"name\": \"player_name\", \"team_x\": \"player_team_name\", \n",
    "                   \"opponent_team\": \"opp_team_id\", 'position_x':'position'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mm5Rzwx-nyHI"
   },
   "source": [
    "# Adding missing opponent team names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "N2AnbiuM358_"
   },
   "outputs": [],
   "source": [
    "# Merging in team info - joins opponent team name (team_name) based on opp_team_id, which is populated in the seasons missing opponent team name\n",
    "df = df.merge(teams, how='left', left_on=['season','opp_team_id'], right_on=['season','team'])\n",
    "\n",
    "# Dropping unnecessary columns\n",
    "df.drop(columns=['team','opp_team_name'], inplace=True)\n",
    "\n",
    "# Renaming opponent team name column\n",
    "df.rename(columns={\"team_name\": \"opp_team_name\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8V44HsrqBkqZ"
   },
   "source": [
    "# Adding opponent difficulty column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "eUUTosdaBhKB"
   },
   "outputs": [],
   "source": [
    "# Importing difficulty data\n",
    "difficulty_data = pd.read_csv(PATH_PREFIX + 'data/team_difficulty_ind.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "8TqwrCHr7V9y"
   },
   "outputs": [],
   "source": [
    "# Joining difficulty data to ours\n",
    "df = df.merge(difficulty_data, how='left', left_on='opp_team_name', right_on='team_name').drop(columns = ['team_name'])\n",
    "\n",
    "# Renaming the opponent difficulty column\n",
    "df.rename(columns={\"FDI\": \"opp_diff_ind\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e77TYgwnpY9k"
   },
   "source": [
    "# Dropping columns we don't plan to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "kaXwD13MpYJc"
   },
   "outputs": [],
   "source": [
    "df.drop(columns=['element', 'fixture', 'transfers_balance','transfers_in' ,'transfers_out'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YnjsCtrxFvd2"
   },
   "source": [
    "# Transforming the \"away and home team score\" columns into a more usable form (player team and opponent team score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "1CgsSoNLFuqk"
   },
   "outputs": [],
   "source": [
    "# Need two new columns: player_team_score and opp_team_score. Populated from team_a_score and team_h_score based on was_home flag\n",
    "df['player_team_score'] = np.where(df['was_home'] == True, df['team_h_score'], df['team_a_score'])\n",
    "df['opp_team_score'] = np.where(df['was_home'] == True, df['team_a_score'], df['team_h_score'])\n",
    "\n",
    "# Drop team_a_score and team_h_score once we have these two columns\n",
    "df.drop(columns=['team_a_score','team_h_score'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GHtj8YTUS7bT"
   },
   "source": [
    "# Dropping Old Seasons and Creating Sequence Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Bg5gnrl_Qyr6"
   },
   "outputs": [],
   "source": [
    "# Katherine note - I think we can delete this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "cda6-fp6TNcZ"
   },
   "outputs": [],
   "source": [
    "df = df.query(\"season != '2017-18'\")\n",
    "df = df.query(\"season != '2016-17'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5AsPvazfTNaU",
    "outputId": "8f89567b-732d-4dd5-a182-c81e6eb90d60"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "season\n",
       "2022-23    26505\n",
       "2021-22    25447\n",
       "2020-21    24365\n",
       "2019-20    22560\n",
       "2018-19    21866\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validating that old seasons are gone - delete at the end\n",
    "df.season.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 690
    },
    "id": "oUy9vnQlTNX-",
    "outputId": "49e19e5f-aa73-414e-9db5-f6c1faf153f0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>player_name</th>\n",
       "      <th>position</th>\n",
       "      <th>player_team_name</th>\n",
       "      <th>assists</th>\n",
       "      <th>bonus</th>\n",
       "      <th>bps</th>\n",
       "      <th>clean_sheets</th>\n",
       "      <th>creativity</th>\n",
       "      <th>goals_conceded</th>\n",
       "      <th>...</th>\n",
       "      <th>value</th>\n",
       "      <th>was_home</th>\n",
       "      <th>yellow_cards</th>\n",
       "      <th>GW</th>\n",
       "      <th>name_normalized</th>\n",
       "      <th>opp_team_name</th>\n",
       "      <th>opp_diff_ind</th>\n",
       "      <th>player_team_score</th>\n",
       "      <th>opp_team_score</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19852</th>\n",
       "      <td>2020-21</td>\n",
       "      <td>Aaron Connolly</td>\n",
       "      <td>FWD</td>\n",
       "      <td>Brighton</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>55</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>aaron connolly</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19853</th>\n",
       "      <td>2020-21</td>\n",
       "      <td>Aaron Cresswell</td>\n",
       "      <td>DEF</td>\n",
       "      <td>West Ham</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>aaron cresswell</td>\n",
       "      <td>Newcastle</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        season      player_name position player_team_name  assists  bonus  \\\n",
       "19852  2020-21   Aaron Connolly      FWD         Brighton        0      0   \n",
       "19853  2020-21  Aaron Cresswell      DEF         West Ham        0      0   \n",
       "\n",
       "       bps  clean_sheets  creativity  goals_conceded  ...  value  was_home  \\\n",
       "19852   -3             0         0.3               2  ...     55      True   \n",
       "19853   11             0        11.2               2  ...     50      True   \n",
       "\n",
       "       yellow_cards GW  name_normalized  opp_team_name  opp_diff_ind  \\\n",
       "19852             0  1   aaron connolly        Chelsea             3   \n",
       "19853             0  1  aaron cresswell      Newcastle             2   \n",
       "\n",
       "       player_team_score  opp_team_score  sequence  \n",
       "19852                1.0             3.0        77  \n",
       "19853                0.0             2.0        77  \n",
       "\n",
       "[2 rows x 35 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add padding so sequence starts counting game weeks from the start\n",
    "\n",
    "season_padding = {\n",
    "    '2018-19': 0,\n",
    "    '2019-20': 38,\n",
    "    '2020-21': 76,\n",
    "    '2021-22': 114,\n",
    "    '2022-23': 152,\n",
    "    '2023-24': 190,\n",
    "}\n",
    "\n",
    "def sequencing(row):\n",
    "  season = row['season']\n",
    "  gw = row['GW']\n",
    "  padding = season_padding.get(season, 0)\n",
    "  row['sequence'] = padding + gw\n",
    "  return row\n",
    "\n",
    "df['sequence'] = 0\n",
    "df = df.apply(sequencing, axis=1)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TIg0-oewBjq7"
   },
   "source": [
    "# Making lagged average columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Pga6mB6YBg0p"
   },
   "outputs": [],
   "source": [
    "# Function to make a DF with lagged features; can input features to lag and number of weeks to lag them\n",
    "def create_lagged_features(df, lag_columns, lag_weeks=3):\n",
    "    # Function to calculate lagged features for a given player and season\n",
    "    def calculate_lags(player_df):\n",
    "        player_df = player_df.sort_values('GW')\n",
    "        for col in lag_columns:\n",
    "            player_df[f'{col}_lag_{lag_weeks}'] = player_df[col].rolling(window=lag_weeks, min_periods=1).mean().shift()\n",
    "        return player_df\n",
    "\n",
    "    lagged_df = df.groupby(['season', 'player_name']).apply(calculate_lags).reset_index(drop=True)\n",
    "\n",
    "    return lagged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "F1VxUInZDe6U"
   },
   "outputs": [],
   "source": [
    "# Columns that we want to lag\n",
    "lag_columns = ['assists', 'bonus', 'bps', 'clean_sheets', 'creativity',\n",
    "               'goals_conceded','goals_scored', 'ict_index', 'influence',\n",
    "               'minutes', 'own_goals', 'penalties_missed', 'penalties_saved',\n",
    "               'red_cards', 'saves', 'selected','player_team_score', 'opp_team_score',\n",
    "               'threat', 'total_points', 'value', 'yellow_cards']\n",
    "\n",
    "# Excluding was_home and opp_diff_ind as these are categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "d0sHQpgUq6DM"
   },
   "outputs": [],
   "source": [
    "# Creating one week lag - will take ~1 minute\n",
    "lagged_df = create_lagged_features(df, lag_columns, lag_weeks = 1)\n",
    "lagged_df = lagged_df.fillna(0)\n",
    "\n",
    "# Replacing current DF with the lagged DF since it includes all of our columns and more\n",
    "df = lagged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "N8fVthqlqNPd"
   },
   "outputs": [],
   "source": [
    "# Creating three week lag - will take ~1 minute\n",
    "lagged_df_three_wk = create_lagged_features(df, lag_columns, lag_weeks = 3)\n",
    "lagged_df_three_wk = lagged_df_three_wk.fillna(0)\n",
    "\n",
    "# Replacing current DF with the lagged DF since it includes all of our columns and more\n",
    "df = lagged_df_three_wk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "5Fe4uOCsxGiw"
   },
   "outputs": [],
   "source": [
    "# Creating five week lag - will take ~1 minute\n",
    "lagged_df_five_wk = create_lagged_features(df, lag_columns, lag_weeks = 5)\n",
    "lagged_df_five_wk = lagged_df_five_wk.fillna(0)\n",
    "\n",
    "# Replacing current DF with the lagged DF since it includes all of our columns and more\n",
    "df = lagged_df_five_wk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQu27rZqfGRC"
   },
   "source": [
    "# Sequence data by season + game week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 342
    },
    "id": "Q2fjPTnk8kNE",
    "outputId": "d3cac95c-976a-4ac0-f5b1-dedf1ed68998"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>player_name</th>\n",
       "      <th>position</th>\n",
       "      <th>player_team_name</th>\n",
       "      <th>assists</th>\n",
       "      <th>bonus</th>\n",
       "      <th>bps</th>\n",
       "      <th>clean_sheets</th>\n",
       "      <th>creativity</th>\n",
       "      <th>goals_conceded</th>\n",
       "      <th>...</th>\n",
       "      <th>penalties_saved_lag_5</th>\n",
       "      <th>red_cards_lag_5</th>\n",
       "      <th>saves_lag_5</th>\n",
       "      <th>selected_lag_5</th>\n",
       "      <th>player_team_score_lag_5</th>\n",
       "      <th>opp_team_score_lag_5</th>\n",
       "      <th>threat_lag_5</th>\n",
       "      <th>total_points_lag_5</th>\n",
       "      <th>value_lag_5</th>\n",
       "      <th>yellow_cards_lag_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-19</td>\n",
       "      <td>Aaron Cresswell</td>\n",
       "      <td>DEF</td>\n",
       "      <td>West Ham</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-19</td>\n",
       "      <td>Aaron Cresswell</td>\n",
       "      <td>DEF</td>\n",
       "      <td>West Ham</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103396.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-19</td>\n",
       "      <td>Aaron Cresswell</td>\n",
       "      <td>DEF</td>\n",
       "      <td>West Ham</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97364.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-19</td>\n",
       "      <td>Aaron Cresswell</td>\n",
       "      <td>DEF</td>\n",
       "      <td>West Ham</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>27.6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88011.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>54.666667</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-19</td>\n",
       "      <td>Aaron Cresswell</td>\n",
       "      <td>DEF</td>\n",
       "      <td>West Ham</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80430.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>54.250000</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    season      player_name position player_team_name  assists  bonus  bps  \\\n",
       "0  2018-19  Aaron Cresswell      DEF         West Ham        0      0    0   \n",
       "1  2018-19  Aaron Cresswell      DEF         West Ham        0      0    0   \n",
       "2  2018-19  Aaron Cresswell      DEF         West Ham        0      0    0   \n",
       "3  2018-19  Aaron Cresswell      DEF         West Ham        0      0   10   \n",
       "4  2018-19  Aaron Cresswell      DEF         West Ham        0      0    0   \n",
       "\n",
       "   clean_sheets  creativity  goals_conceded  ...  penalties_saved_lag_5  \\\n",
       "0             0         0.0               0  ...                    0.0   \n",
       "1             0         0.0               0  ...                    0.0   \n",
       "2             0         0.0               0  ...                    0.0   \n",
       "3             0        27.6               1  ...                    0.0   \n",
       "4             0         0.0               0  ...                    0.0   \n",
       "\n",
       "   red_cards_lag_5  saves_lag_5 selected_lag_5  player_team_score_lag_5  \\\n",
       "0              0.0          0.0       0.000000                 0.000000   \n",
       "1              0.0          0.0  103396.000000                 0.000000   \n",
       "2              0.0          0.0   97364.500000                 0.500000   \n",
       "3              0.0          0.0   88011.666667                 0.666667   \n",
       "4              0.0          0.0   80430.000000                 0.500000   \n",
       "\n",
       "   opp_team_score_lag_5  threat_lag_5  total_points_lag_5  value_lag_5  \\\n",
       "0                   0.0           0.0                0.00     0.000000   \n",
       "1                   4.0           0.0                0.00    55.000000   \n",
       "2                   3.0           0.0                0.00    55.000000   \n",
       "3                   3.0           0.0                0.00    54.666667   \n",
       "4                   2.5           0.0                0.25    54.250000   \n",
       "\n",
       "   yellow_cards_lag_5  \n",
       "0                0.00  \n",
       "1                0.00  \n",
       "2                0.00  \n",
       "3                0.00  \n",
       "4                0.25  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "sn2QTJTMfGfz"
   },
   "outputs": [],
   "source": [
    "df = df.sort_values(['season','player_name','GW'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "Nl5RJRkvX8fe"
   },
   "outputs": [],
   "source": [
    "df.to_csv(PATH_PREFIX + 'data/sample.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_8ySN7rezxs"
   },
   "source": [
    "# Splitting into minutes DF and overall DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "gfUmODMEezxt"
   },
   "outputs": [],
   "source": [
    "# Katherine note - commenting this out for now in case we want to do this in the modeling notebooks, but it's easy to add back in\n",
    "\n",
    "# minutes = df[df['minutes'] > 0]\n",
    "# After this, minutes is a DF with only players who played and df is a DF with all players (regardless of minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZhqroJAI5CUd"
   },
   "source": [
    "# Dropping columns we won't use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "ARnVeAwpLjOV"
   },
   "outputs": [],
   "source": [
    "# We don't have to do this; could do it in modeling notebooks. But I (Katherine) think this'll be cleaner\n",
    "\n",
    "# Dropping columns that aren't useful\n",
    "# df.drop(columns=['player_name', 'kickoff_time', 'opp_team_id', 'round', 'name_normalized', 'sequence'], inplace=True) \n",
    "df.drop(columns=['player_name', 'kickoff_time', 'opp_team_id', 'round'], inplace=True) \n",
    "# Sequence is coming from Hisham's code - if we drop that section, we need to remove the column from this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "nhmnxEtn5CbL"
   },
   "outputs": [],
   "source": [
    "# Dropping all unlagged continuous columns except the target\n",
    "lag_columns.remove('total_points')\n",
    "\n",
    "df.drop(columns=lag_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xHh4Jyf1UPxp"
   },
   "source": [
    "# Split data into train/validation/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "hf-fhf_rUP4w"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yc/p4crn8cj0tz82_rx5_032qvw0000gn/T/ipykernel_93589/2091538429.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train_init.drop(columns=['total_points'], inplace=True)\n",
      "/var/folders/yc/p4crn8cj0tz82_rx5_032qvw0000gn/T/ipykernel_93589/2091538429.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_val_init.drop(columns=['total_points'], inplace=True)\n",
      "/var/folders/yc/p4crn8cj0tz82_rx5_032qvw0000gn/T/ipykernel_93589/2091538429.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test_init.drop(columns=['total_points'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "X_train_init = df[df['season'].isin(['2018-19','2019-20','2020-21'])]\n",
    "Y_train = X_train_init[['name_normalized', 'total_points']]\n",
    "X_train_init.drop(columns=['total_points'], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Validation\n",
    "X_val_init = df[df['season'].isin(['2021-22'])]\n",
    "Y_val = X_val_init[['name_normalized', 'total_points']]\n",
    "X_val_init.drop(columns=['total_points'], inplace=True)\n",
    "\n",
    "\n",
    "# Test\n",
    "X_test_init = df[df['season'].isin(['2022-23'])]\n",
    "Y_test = X_test_init[['name_normalized', 'total_points']]\n",
    "X_test_init.drop(columns=['total_points'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l4TJUquu6L3P",
    "outputId": "574c2694-4281-4d39-e2b8-d1234f7a8bfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68791, 75)\n",
      "(68791, 2)\n",
      "(25447, 75)\n",
      "(25447, 2)\n",
      "(26505, 75)\n",
      "(26505, 2)\n"
     ]
    }
   ],
   "source": [
    "# QCing train/test/val shapes - delete at the end\n",
    "print(X_train_init.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_val_init.shape)\n",
    "print(Y_val.shape)\n",
    "print(X_test_init.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h8vh8gqG_NLO"
   },
   "source": [
    "# Standardize lagged features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "IQ9VP4HA6pVJ"
   },
   "outputs": [],
   "source": [
    "# Pulling out only the features to be standardized\n",
    "categorical_vars = ['season','player_team_name','opp_team_name','opp_diff_ind','position','GW','was_home', \n",
    "                    'sequence', 'name_normalized']\n",
    "_cat_vars = categorical_vars[:-2]\n",
    "\n",
    "X_train_contin = X_train_init.loc[:, ~X_train_init.columns.isin(categorical_vars)]\n",
    "X_val_contin = X_val_init.loc[:, ~X_val_init.columns.isin(categorical_vars)]\n",
    "X_test_contin = X_test_init.loc[:, ~X_test_init.columns.isin(categorical_vars)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "JhyLTO-pT_q4"
   },
   "outputs": [],
   "source": [
    "# Standardizing the continuous variables\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the train features\n",
    "train_features = scaler.fit_transform(X_train_contin)\n",
    "\n",
    "# Only transform the validation and test features\n",
    "val_features = scaler.transform(X_val_contin)\n",
    "test_features = scaler.transform(X_test_contin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CKe31UhcyQJI",
    "outputId": "8ae7d645-b8ef-4743-d4f7-aa61dd63dd5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25447, 66)\n",
      "(25447, 66)\n"
     ]
    }
   ],
   "source": [
    "print(X_val_contin.shape)\n",
    "print(val_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "ouwxQ-LR-Hm8"
   },
   "outputs": [],
   "source": [
    "# Turn the standardized arrays back into DFs and add the column names back in\n",
    "X_train_temp = pd.DataFrame(train_features, columns=X_train_contin.columns)\n",
    "X_val_temp = pd.DataFrame(val_features, columns=X_val_contin.columns)\n",
    "X_test_temp = pd.DataFrame(test_features, columns=X_test_contin.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "73brhBfuAXdB"
   },
   "outputs": [],
   "source": [
    "# Join the categorical variables back\n",
    "X_train = pd.concat([X_train_init[categorical_vars],X_train_temp], axis=1)\n",
    "X_val = pd.concat([X_val_init[categorical_vars].reset_index(drop=True),X_val_temp], axis=1)\n",
    "X_test = pd.concat([X_test_init[categorical_vars].reset_index(drop=True),X_test_temp], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ks014O12GqzI",
    "outputId": "4dd8db7a-24ae-4093-b929-7e4df9a25492"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68791, 75)\n",
      "(68791, 75)\n",
      "(68791, 2)\n",
      "(25447, 75)\n",
      "(25447, 75)\n",
      "(25447, 2)\n",
      "(26505, 75)\n",
      "(26505, 75)\n",
      "(26505, 2)\n"
     ]
    }
   ],
   "source": [
    "# QCing train/test/val shapes post-standardization - delete at the end\n",
    "print(X_train_init.shape)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_val_init.shape)\n",
    "print(X_val.shape)\n",
    "print(Y_val.shape)\n",
    "print(X_test_init.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhXNx5E-UEUL"
   },
   "source": [
    "# Transform categorical variables into one-hot encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "b4L9UT8OH_Rn"
   },
   "outputs": [],
   "source": [
    "# Right now, I only kept the dense one-hot encodings because I think they'll be\n",
    "# easiest to work with, but I'm happy to replace with sparse or embeddings if\n",
    "# someone wants to switch out the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "-9Sos02vfqmp"
   },
   "outputs": [],
   "source": [
    "# Code from https://medium.com/@roeibahumi/keras-regression-with-categorical-variable-embeddings-dfc28616e7fe\n",
    "\n",
    "class EmbeddingMapping():\n",
    "    \"\"\"\n",
    "    Helper class for handling categorical variables\n",
    "\n",
    "    An instance of this class should be defined for each categorical variable we want to use.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, series):\n",
    "        # get a list of unique values\n",
    "        values = series.unique().tolist()\n",
    "\n",
    "        # Set a dictionary mapping from values to integer value\n",
    "        self.embedding_dict = {value: int_value + 1 for int_value, value in enumerate(values)}\n",
    "\n",
    "        # The num_values will be used as the input_dim when defining the embedding layer.\n",
    "        # It will also be returned for unseen values\n",
    "        self.num_values = len(values) + 1\n",
    "\n",
    "    def get_mapping(self, value):\n",
    "        # If the value was seen in the training set, return its integer mapping\n",
    "        if value in self.embedding_dict:\n",
    "            return self.embedding_dict[value]\n",
    "\n",
    "        # Else, return the same integer for unseen values\n",
    "        else:\n",
    "            return self.num_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "3NyFOOfrmuSW"
   },
   "outputs": [],
   "source": [
    "# Transforming categorical variables into one-hot encodings\n",
    "\n",
    "# I can't get an iteration to work, so I'm doing it manually since there are only 5 - delete this comment at the end\n",
    "\n",
    "season_mapping = EmbeddingMapping(X_train['season']) # This should only happen on train\n",
    "X_train = X_train.assign(season_mapping=X_train['season'].apply(season_mapping.get_mapping)) # This should happen separately for train and val/test\n",
    "X_val = X_val.assign(season_mapping=X_val['season'].apply(season_mapping.get_mapping))\n",
    "X_test = X_test.assign(season_mapping=X_test['season'].apply(season_mapping.get_mapping))\n",
    "\n",
    "player_team_name_mapping = EmbeddingMapping(X_train['player_team_name'])\n",
    "X_train = X_train.assign(player_team_name_mapping=X_train['player_team_name'].apply(player_team_name_mapping.get_mapping))\n",
    "X_val = X_val.assign(player_team_name_mapping=X_val['player_team_name'].apply(player_team_name_mapping.get_mapping))\n",
    "X_test = X_test.assign(player_team_name_mapping=X_test['player_team_name'].apply(player_team_name_mapping.get_mapping))\n",
    "\n",
    "opp_team_name_mapping = EmbeddingMapping(X_train['opp_team_name'])\n",
    "X_train = X_train.assign(opp_team_name_mapping=X_train['opp_team_name'].apply(opp_team_name_mapping.get_mapping))\n",
    "X_val = X_val.assign(opp_team_name_mapping=X_val['opp_team_name'].apply(opp_team_name_mapping.get_mapping))\n",
    "X_test = X_test.assign(opp_team_name_mapping=X_test['opp_team_name'].apply(opp_team_name_mapping.get_mapping))\n",
    "\n",
    "opp_diff_ind_mapping = EmbeddingMapping(X_train['opp_diff_ind'])\n",
    "X_train = X_train.assign(opp_diff_ind_mapping=X_train['opp_diff_ind'].apply(opp_diff_ind_mapping.get_mapping))\n",
    "X_val = X_val.assign(opp_diff_ind_mapping=X_val['opp_diff_ind'].apply(opp_diff_ind_mapping.get_mapping))\n",
    "X_test = X_test.assign(opp_diff_ind_mapping=X_test['opp_diff_ind'].apply(opp_diff_ind_mapping.get_mapping))\n",
    "\n",
    "position_mapping = EmbeddingMapping(X_train['position'])\n",
    "X_train = X_train.assign(position_mapping=X_train['position'].apply(position_mapping.get_mapping))\n",
    "X_val = X_val.assign(position_mapping=X_val['position'].apply(position_mapping.get_mapping))\n",
    "X_test = X_test.assign(position_mapping=X_test['position'].apply(position_mapping.get_mapping))\n",
    "\n",
    "gw_mapping = EmbeddingMapping(X_train['GW'])\n",
    "X_train = X_train.assign(gw_mapping=X_train['GW'].apply(gw_mapping.get_mapping))\n",
    "X_val = X_val.assign(gw_mapping=X_val['GW'].apply(gw_mapping.get_mapping))\n",
    "X_test = X_test.assign(gw_mapping=X_test['GW'].apply(gw_mapping.get_mapping))\n",
    "\n",
    "was_home_mapping = EmbeddingMapping(X_train['was_home'])\n",
    "X_train = X_train.assign(was_home_mapping=X_train['was_home'].apply(was_home_mapping.get_mapping))\n",
    "X_val = X_val.assign(was_home_mapping=X_val['was_home'].apply(was_home_mapping.get_mapping))\n",
    "X_test = X_test.assign(was_home_mapping=X_test['was_home'].apply(was_home_mapping.get_mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "e0ttqY-qNnvQ"
   },
   "outputs": [],
   "source": [
    "# Dropping the unmapped categorical variable columns\n",
    "X_train.drop(columns=_cat_vars, inplace=True)\n",
    "X_val.drop(columns=_cat_vars, inplace=True)\n",
    "X_test.drop(columns=_cat_vars, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tKOKuir02Gua"
   },
   "source": [
    "# Exporting CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_normalized</th>\n",
       "      <th>total_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aaron cresswell</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aaron cresswell</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aaron cresswell</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aaron cresswell</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aaron cresswell</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68786</th>\n",
       "      <td>rjan nyland</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68787</th>\n",
       "      <td>rjan nyland</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68788</th>\n",
       "      <td>rjan nyland</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68789</th>\n",
       "      <td>rjan nyland</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68790</th>\n",
       "      <td>rjan nyland</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68791 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       name_normalized  total_points\n",
       "0      aaron cresswell             0\n",
       "1      aaron cresswell             0\n",
       "2      aaron cresswell             0\n",
       "3      aaron cresswell             1\n",
       "4      aaron cresswell             0\n",
       "...                ...           ...\n",
       "68786      rjan nyland             0\n",
       "68787      rjan nyland             0\n",
       "68788      rjan nyland             0\n",
       "68789      rjan nyland             0\n",
       "68790      rjan nyland             0\n",
       "\n",
       "[68791 rows x 2 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GrHjxmSeMzuo"
   },
   "outputs": [],
   "source": [
    "# # Turning labels into DFs so we can export them\n",
    "# Y_train = pd.DataFrame(Y_train, columns=['total_points'])\n",
    "# Y_val = pd.DataFrame(Y_val, columns=['total_points'])\n",
    "# Y_test = pd.DataFrame(Y_test, columns=['total_points'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "Xe_WJHN8fTyB"
   },
   "outputs": [],
   "source": [
    "X_train.to_csv(PATH_PREFIX + 'data/X_train.csv', encoding='utf-8')\n",
    "Y_train.to_csv(PATH_PREFIX + 'data/Y_train.csv', encoding='utf-8')\n",
    "X_val.to_csv(PATH_PREFIX + 'data/X_val.csv', encoding='utf-8')\n",
    "Y_val.to_csv(PATH_PREFIX + 'data/Y_val.csv', encoding='utf-8')\n",
    "X_test.to_csv(PATH_PREFIX + 'data/X_test.csv', encoding='utf-8')\n",
    "Y_test.to_csv(PATH_PREFIX + 'data/Y_test.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YUU4gC0qMgtu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
